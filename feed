<?xml version="1.0" encoding="UTF-8"?>
<feed xml:lang="en-US" xmlns="http://www.w3.org/2005/Atom">
  <id>tag:blog.felixangell.com,2014:/feed</id>
  <link rel="alternate" type="text/html" href="https://blog.felixangell.com"/>
  <link rel="self" type="application/atom+xml" href="https://blog.felixangell.com/feed"/>
  <title>Felix Angell</title>
  <updated>2019-04-25T15:18:44-07:00</updated>
  <author>
    <name>Felix Angell</name>
    <uri>http://blog.felixangell.com</uri>
  </author>
  <generator>Svbtle.com</generator>
  <entry>
    <id>tag:blog.felixangell.com,2014:Post/compilers-brief-and-brisk</id>
    <published>2019-04-25T15:18:44-07:00</published>
    <updated>2019-04-25T15:18:44-07:00</updated>
    <link rel="alternate" type="text/html" href="http://blog.felixangell.com/compilers-brief-and-brisk"/>
    <title>A Brief &amp;amp; Brisk Overview of Compiler Architecture</title>
    <content type="html">&lt;p&gt;Most compilers out there follow a particular architecture:&lt;/p&gt;

&lt;p&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/c/cc/Compiler_design.svg" alt=""&gt;&lt;/p&gt;

&lt;p&gt;The above is a very abstract view of a typical compiler architecture, it was the only ‚Äòlabelled for reuse‚Äô diagram I could find in 5 seconds - sorry!&lt;/p&gt;

&lt;p&gt;In this article I intend to dissect this architecture piece by piece in some detail. Consider this article a supplement to the plethora of resources out there on compilers. Perhaps this will exist as a self contained resource to get your toes wet in the world of programming language design and implementation. The audience for this article is someone who has very limited knowledge as to how a compiler works. Though it is written in a way that you are a competent programmer and have a good knowledge of data structures and algorithms.&lt;/p&gt;

&lt;p&gt;Currently, I‚Äôm working on a programming language called &lt;a href="https://krug-lang.org"&gt;Krug&lt;/a&gt;, which is a systems programming language that takes a lot of inspiration from Rust and Go. I‚Äôll be referencing Krug a few times in this article to compare and help illustrate my points. Krug is still under very heavy development, but you can find it on GitHub under the ‚Äòhugobrains‚Äô organisation as &lt;a href="https://github.com/hugobrains/caasper"&gt;caasper&lt;/a&gt;, and &lt;a href="https://github.com/hugobrains/krug"&gt;krug&lt;/a&gt;.&lt;br&gt;
The language itself is a bit unusual compared to the typical architecture of compilers, though this will be touched on more near the end of this article!&lt;/p&gt;

&lt;p&gt;I would like to disclaim that I am by no means an expert in compilers! I don‚Äôt have a doctorate in Compilers, I did not study this at an academic level in any way - most of what I am sharing is what I have learned in my spare time for fun. In addition, I am not claiming what I write to be the de-facto approach for engineering a compiler, but rather introducing approaches that would be applicable for a small toy compiler.&lt;/p&gt;
&lt;h2 id="frontend_2"&gt;Frontend &lt;a class="head_anchor" href="#frontend_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Referring back to the previous diagram, the arrows on the left pointing into the box are programming languages we all know and love today - like C! The frontend looks something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;Lexical Analysis -&amp;gt; Parser
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="lexical-analysis_3"&gt;Lexical Analysis &lt;a class="head_anchor" href="#lexical-analysis_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;When I was first learning about compilers and language design, this was described to me as a ‚Äòfancy way of saying tokenization‚Äô. So let‚Äôs go with that. The ‚Äòlexer‚Äô typically takes input in a form of strings or a stream of characters, and recognizes patterns in those characters to cut them up into tokens. The strings themselves are usually stored in the token as a ‚Äòlexeme‚Äô:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;enum TokenType {
    Identifier,
    Number,
};

struct Token {
    std::string Lexeme;
    TokenType type;

    // ...
    // It's also handy to store things in here
    // like the position of the token (start to end row:col)
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This post isn‚Äôt necessarily a guide to creating a language with code samples, but I will add a few bits code snippets here and there to assist translating these ideas.&lt;/p&gt;

&lt;p&gt;In the above snippet of some kind of C-like language, we have a Token structure which contains the aforementioned &lt;code class="prettyprint"&gt;lexeme&lt;/code&gt;, as well as a TokenType to distinguish what kind of lexeme is stored.&lt;/p&gt;

&lt;p&gt;Lexers are usually the easiest part of the compiler to make, in fact the entire frontend is usually quite simple relative to the other pieces of the puzzle. Though this depends on how hard you can make it for yourself üòâ&lt;/p&gt;

&lt;p&gt;Take the following piece of C code:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;int main() {
    printf("Hello world!\n");
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you were to read this from a file into a string, and then linearly scan through the string you could probably cut these into tokens. We naturally identify these tokens looking at the language ourselves, e.g. it‚Äôs clear that &lt;code class="prettyprint"&gt;int&lt;/code&gt; is a ‚Äúword‚Äù, and &lt;code class="prettyprint"&gt;0&lt;/code&gt; in the return statement is a ‚Äúnumber‚Äù.&lt;br&gt;
The lexer does the same kind of thing, and we can go into as much detail as necessary to ease the process later. For example, you could lex:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;0xdeadbeef
1231234234
3.1412
55.5555
0b0001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As ‚Äúnumbers‚Äù, or you could categorize them further as:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;0xdeadbeef      HexNumber
1231234234      WholeNumber
3.1412          FloatingNumber
55.5555         FloatingNumber
0b0001          BinaryNumber
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As for defining ‚Äúwords‚Äù, it can be difficult. Most languages define a word as a grouping of letters and digits, the identifier typically must &lt;u&gt;start&lt;/u&gt; with a letter (or an underscore), e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;123foobar := 3
person-age := 5
fmt.Println(123foobar)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Is &lt;strong&gt;not&lt;/strong&gt; valid Go code as it is probably parsed into these tokens:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;Number(123), Identifier(123), Symbol(:=), Number(3) ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Most identifiers that we encounter are of the form:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;foo_bar
__uint8_t
fooBar123
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lexers will also have to deal with other problems, e.g.:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Whitespace,&lt;/li&gt;
&lt;li&gt;Comments - Multi Line and Single Line,&lt;/li&gt;
&lt;li&gt;Identifiers,&lt;/li&gt;
&lt;li&gt;Numbers, bases, number ‚Äòformatting‚Äô, e.g. &lt;code class="prettyprint"&gt;1_000_000&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;Input encoding, e.g. supporting UTF8 rather than ASCII&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;‚Ä¶ and before you think about using regular expressions to do this, I would not recommend it! It‚Äôs much easier to write a lexer from scratch, but I highly recommend reading this &lt;a href="https://commandcenter.blogspot.com/2011/08/regular-expressions-in-lexing-and.html"&gt;blog post&lt;/a&gt; from our lord and saviour Rob Pike. &lt;br&gt;
Though, there are many articles on why Regex is not the right tool for the job so I think I‚Äôll skim over that segment for this article.&lt;br&gt;
It‚Äôs also a lot more fun to write a lexer than it is pulling your hair out over a long winded regular expression you have pasted into regex101.com at 5:24 in the morning.&lt;/p&gt;

&lt;p&gt;My first ‚Äòprogramming language‚Äô I used the &lt;code class="prettyprint"&gt;split(str)&lt;/code&gt; function to tokenize my input - I didn‚Äôt get very far.&lt;/p&gt;
&lt;h3 id="parsing_3"&gt;Parsing &lt;a class="head_anchor" href="#parsing_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Parsing is a bit more of a complicated beast compared to Lexical Analysis. There are many kinds of parsers out there and parser generators. This is where things start to get a bit more serious.&lt;/p&gt;

&lt;p&gt;In compilers, a parser will usually take an input of tokens, and produce a tree of some sort. This could be an ‚ÄòAbstract Syntax Tree‚Äô, or a ‚ÄòParse Tree‚Äô. Both of which are similar at the core, but do share differences.&lt;/p&gt;

&lt;p&gt;You could think of these stages so far as functions:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;fn lex(string input) []Token {...}
fn parse(tokens []Token) AST {...}

let input = "int main() { return 0; }";
let tokens = lex(input);
let parse_tree = parse(tokens);
// ....
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Compilers are usually built up in lots of little components which take inputs and mutate them or convert them into different outputs. Which is partly why functional languages are very good for creating compilers!&lt;br&gt;
Fun fact: the first implementation of the &lt;a href="https://en.wikipedia.org/wiki/Rust_(programming_language)"&gt;Rust&lt;/a&gt; compiler was implemented in OCaml.&lt;br&gt;
And a piece of advice is to keep these components as self contained and simple as possible, keeping everything modular simplifies the entire process. I feel as if this philosophy applies to many aspects of software engineering however.&lt;/p&gt;
&lt;h3 id="trees_3"&gt;Trees! &lt;a class="head_anchor" href="#trees_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;&lt;h4 id="parse-tree_4"&gt;Parse Tree &lt;a class="head_anchor" href="#parse-tree_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;WTF is‚Ä¶ - a parse tree? Sometimes referred to as a ‚Äòsyntax tree‚Äô, is a much more dense tree that represents the source program. They contain &lt;u&gt;all&lt;/u&gt; (or most) of the information of the input program, usually matching what is described in the grammar of your language.&lt;/p&gt;
&lt;h4 id="abstract-syntax-tree_4"&gt;Abstract Syntax Tree &lt;a class="head_anchor" href="#abstract-syntax-tree_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;The Abstract Syntax Tree (AST) is, as the name suggests, an ‚Äòabstract‚Äô syntax tree. The Parse Tree contains a lot of (possibly superfluous) information about your program. The point of the AST is that we don‚Äôt need all of this information to do our job. It throws away a lot of the useless structural/grammatical information that doesn‚Äôt contribute to the semantics of the program.&lt;br&gt;
For example, perhaps you have an expression in your tree &lt;u&gt;Parse Tree&lt;/u&gt; like &lt;code class="prettyprint"&gt;((5 + 5) - 3) + 2&lt;/code&gt;. You would store the parenthesis in the Parse Tree, and maybe that the values 5, 5, 3, and 2 are atoms, but once you can derive the associations, you can abstract away these details in the AST as we only need to know the values and their operators as well as the order of the operations.&lt;/p&gt;

&lt;p&gt;Here‚Äôs another free for re-use image I found that shows the AST for &lt;code class="prettyprint"&gt;a + b / c&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/6/68/Parsing_Example.png" alt="a + b / c in the form of a tree"&gt;&lt;/p&gt;

&lt;p&gt;An AST could be represented as such:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;interface Expression { ... };

struct UnaryExpression {
    Expression value;
    char op;
};

struct BinaryExpression {
    Expression lhand, rhand;
    string op; // string because the op could be more than 1 char.
};

interface Node { ... };

// or for something like a variable
struct Variable : Node {
    Token identifier;
    Expression value;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is a very limited representation of an AST, but you could hopefully see how you would structure your nodes.&lt;/p&gt;

&lt;p&gt;As for parsing them, you could have a procedure like:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;Node parseNode() {
    Token current = consume();
    switch (current.lexeme) {
    case "var":
        return parseVariableNode();
    // ...
    }
    panic("unrecognized input!");
}

Node n = parseNode();
if (n != null) {
    // append to some list of top level nodes?
    // or append to a block of nodes!
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="grammars_3"&gt;Grammars &lt;a class="head_anchor" href="#grammars_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;To parse from a set of tokens into an AST can be a tricky task. Usually you would start with some kind of grammar for your language.&lt;/p&gt;

&lt;p&gt;Grammar is basically a definition of how a language is structured. There are a few languages for defining languages, which can be described (or bootstrapped) with themselves.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form"&gt;Extended Backus-Naur Form&lt;/a&gt; (EBNF) is an example of a language for defining languages. It is based off &lt;a href="https://dlang.org/spec/grammar.html"&gt;BNF&lt;/a&gt; which is a bit more angle bracket-y.&lt;/p&gt;

&lt;p&gt;Here‚Äôs an example of some EBNF taken from the Wikipedia Article:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;digit excluding zero = "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" ;
digit                = "0" | digit excluding zero ;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Production rules are defined, which tell the reader what pattern of terminals make up what ‚Äònonterminal‚Äô. Terminals are part of the grammars alphabet, e.g. the token ‚Äúif‚Äù, or in the example above ‚Äú0‚Äù and ‚Äú1‚Äù are terminals. Non-terminals are the opposite, they are on the left of the production rules, and can be considered variables or ‚Äònamed references‚Äô to a grouping of terminals &lt;u&gt;and&lt;/u&gt; non terminals.&lt;/p&gt;

&lt;p&gt;Many languages have specifications, which contain their grammars that you can read. Here is &lt;a href="https://golang.org/ref/spec#Function_declarations"&gt;Golangs&lt;/a&gt;, and &lt;a href="https://doc.rust-lang.org/reference/"&gt;Rust&lt;/a&gt;, as well as &lt;a href="https://dlang.org/spec/grammar.html"&gt;D&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id="recursive-descent-parsing_4"&gt;Recursive Descent Parsing &lt;a class="head_anchor" href="#recursive-descent-parsing_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;The easiest approach is using a ‚Äòrecursive descent parser‚Äô. There are many approaches to parsing, and this is one of them.&lt;/p&gt;

&lt;p&gt;Recursive descent is a top down parser built from a set of recursive procedures. It‚Äôs a much simpler to write parser, given that your grammar has no &lt;a href="https://en.wikipedia.org/wiki/Left_recursion"&gt;left recursion&lt;/a&gt;. For most hobby/toy languages, it‚Äôs a sufficient technique for parsing. GCC uses a hand-written recursive descent parser, though it has used YACC before.&lt;br&gt;
Though there can be issues with parsing these languages, especially something like C, where:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;foo * bar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Could be interpreted as:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;int foo = 3;
int bar = 4;
foo * bar; // unused expression
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or it could be interpreted as:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;typedef struct {
    int b;
} foo;
foo* bar;
bar.b = 3;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href="https://clang.llvm.org/features.html"&gt;Clang&lt;/a&gt; also uses a recursive-descent parser in its implementation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;span class="accent-dot"&gt;&lt;/span&gt;&lt;p&gt;Because it is plain C++ code, recursive descent makes it very easy for new developers to understand the code, it easily supports ad-hoc rules and other strange hacks required by C/C++, and makes it straightforward to implement excellent diagnostics and error recovery.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A few approaches that are worth reading into are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;LL, Recursive descent&lt;/li&gt;
&lt;li&gt;LR, shift reduce, recursive ascent, ‚Ä¶&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="parser-generators_4"&gt;Parser Generators! &lt;a class="head_anchor" href="#parser-generators_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;Parser generators are a very good approach to take too. There are trade offs though, as there are with any choice you make when creating a piece of software.&lt;/p&gt;

&lt;p&gt;Parser generators are usually very fast, they are a lot easier than writing your own parser (and getting a performant result from it), though they are usually not very user friendly, and don‚Äôt allow for great error messages. In addition, you then have to learn how to use your parser generator, as well as when it comes to bootstrapping your compiler, you probably have to bootstrap your parser generator too.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.antlr.org/"&gt;ANTLR&lt;/a&gt; is an example of a parser generator, though there are plenty more out there.&lt;/p&gt;

&lt;p&gt;I think they are a tool for when you don‚Äôt want to focus on writing the frontend, but would rather get on with writing the middle and the backend parts of your compiler/interpreter, or dealing with whatever else you want to parse.&lt;/p&gt;
&lt;h4 id="the-application-of-parsing_4"&gt;The Application of Parsing &lt;a class="head_anchor" href="#the-application-of-parsing_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;If you haven‚Äôt guessed yet. Just the frontend of a compiler is &lt;u&gt;very&lt;/u&gt; applicable to other problems:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Syntax highlighting;&lt;/li&gt;
&lt;li&gt;HTML/CSS parsing for a layout engine&lt;/li&gt;
&lt;li&gt;Transpilers: TypeScript, CoffeeScript&lt;/li&gt;
&lt;li&gt;Assemblers&lt;/li&gt;
&lt;li&gt;REGEX&lt;/li&gt;
&lt;li&gt;Screen scraping&lt;/li&gt;
&lt;li&gt;URL parsing&lt;/li&gt;
&lt;li&gt;Formatting tools like &lt;code class="prettyprint"&gt;gofmt&lt;/code&gt;
&lt;/li&gt;
&lt;li&gt;SQL parsing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And much more.&lt;/p&gt;
&lt;h2 id="the-middle_2"&gt;The Middle &lt;a class="head_anchor" href="#the-middle_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Semantic analysis! Analyzing the semantics of the language is one of the harder parts of compiler design.&lt;br&gt;
It involves ensuring that the programs are &lt;u&gt;correct&lt;/u&gt;. Krug is lacking in the semantic analysis aspects currently, and without it the programmer would be trusted to write code that is correct all the time. But in reality this is never the case and we‚Äôre always writing, compiling, (maybe running), and fixing errors in a loop.&lt;br&gt;
Not only this, but it can be impossible to compile programs if you can‚Äôt analyze that the semantics are correct in this analysis phase of the compiler.&lt;/p&gt;

&lt;p&gt;I remember reading a diagram a while ago that showed the percentages of the front, middle, and back ends of a compiler and how they were split up and it was something like:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;F: 20% M: 20%: B: 60%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But I feel like nowadays it‚Äôs leaning more to:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;F: 5% M: 60% B: 35%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Frontends are mostly the job of a generator or can be done very quickly to a language that is mostly context free and/or doesn‚Äôt have any ambiguities in the grammar (throw a recursive descent parser at it!).&lt;/p&gt;

&lt;p&gt;With frameworks like LLVM, most of the work of optimisation can be offloaded onto LLVM, already providing a plethora of optimisations out of the box! So that leads us with semantic analysis which is a very integral part of the compilation phase. For example, a language like &lt;a href="https://en.wikipedia.org/wiki/Rust_(programming_language)"&gt;Rust&lt;/a&gt; with it‚Äôs ownership memory model mostly acts as a big fancy machine that performs all types of static analysis.&lt;/p&gt;

&lt;p&gt;Because of this, semantic analysis is definitely eating up a lot of the focus for compiler architecture since a lot of the tedious ground work like optimising generated assembly, or readng input into a tree is done for you. &lt;/p&gt;
&lt;h3 id="semantic-passes_3"&gt;Semantic Passes &lt;a class="head_anchor" href="#semantic-passes_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Most compilers will perform a large amount of ‚Äòsemantic passes‚Äô over the AST (or some abstract form to represent the code) during semantic analysis. &lt;a href="https://blogs.msdn.microsoft.com/ericlippert/2010/02/04/how-many-passes/"&gt;This&lt;/a&gt; article goes into detail about most of the passes that are performed in the .NET C# compiler (from 2010).&lt;/p&gt;

&lt;p&gt;I won‚Äôt go over every pass that could be implemented, especially since this varies on the language you are implementing for, but below are a few passes that are in my language &lt;a href="https://krug-lang.org"&gt;Krug&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="39top-level39-declaration-pass_3"&gt;‚ÄòTop Level‚Äô Declaration Pass &lt;a class="head_anchor" href="#39top-level39-declaration-pass_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;The compiler will go over all of the ‚Äòtop level‚Äô declarations in the modules and acknowledge that they exist. It‚Äôs top level as it doesn‚Äôt go any further into blocks, it will simply declare what structures, functions, etc. exist in what module.&lt;/p&gt;
&lt;h3 id="namesymbol-resolution_3"&gt;Name/Symbol Resolution &lt;a class="head_anchor" href="#namesymbol-resolution_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;This pass will go through all of the blocks of code in the functions, etc. and resolve them, i.e. find the symbols that they resolve to. This is a common pass, and is usually where the error &lt;code class="prettyprint"&gt;No such symbol XYZ&lt;/code&gt; comes from when you compile your Go code.&lt;/p&gt;

&lt;p&gt;This can be a very tricky pass to do, especially if you have cyclic dependencies in your dependency graph. Some languages do not allow for cycles, e.g. Krug. In addition, Go will also error if you have packages that form a cycle.&lt;/p&gt;

&lt;p&gt;Cycles can be detected by modifying a DFS on the dependency graph, or you can use &lt;a href="https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm"&gt;Tarjans Strongly Connected Components algorithm&lt;/a&gt; (like Krug) to identify (multiple) cycles in a dependency graph.&lt;/p&gt;
&lt;h3 id="type-inference_3"&gt;Type Inference &lt;a class="head_anchor" href="#type-inference_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;There is a pass in the compiler that will go through all variables infer their types. The type inference in Krug is very weak, it is simply inferring the variable based off the value it contains. There is, by no means, a fancy type system like the one you would find in a function language like Haskell.&lt;/p&gt;

&lt;p&gt;Type inference can be done using a process called ‚Äòunification‚Äô, or ‚Äòtype unification‚Äô. Though you can have some very simple implementations for simpler type systems.&lt;/p&gt;

&lt;p&gt;Types in Krug are implemented as such:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;interface Type {};

struct IntegerType : Type {
    int width;
    bool signed;
};

struct FloatingType : Type {
    int width;
};

struct ArrayType : Type {
    Type base_type;
    uint64 length;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And you could have some simple type inference where you would assign expression nodes a type, e.g. an IntegerConstantNode would have the type IntegerType(64). And then you have a function unify(t1, t2) which picks the widest type that can be used for inferring the type of more complex expressions like a BinaryExpression. Then it‚Äôs a matter of assigning the left hand variable the right hand values inferred type.&lt;br&gt;
A while back I wrote a simple &lt;a href="https://github.com/felixangell/type-inference"&gt;type inferrer&lt;/a&gt; in Go that prototyped how Krugs inference would be implemented.&lt;/p&gt;
&lt;h3 id="mutability-pass_3"&gt;Mutability Pass &lt;a class="head_anchor" href="#mutability-pass_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Krug is (like Rust) an immutable by default language, meaning that variables are constant unless specified:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;let x = 3;
x = 4; // BAD!

mut y = 5;
y = 6; // OK!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This pass in the compiler will run through all of the blocks and functions and ensure that they are ‚Äòconst correct‚Äô, i.e. we are not mutating anything we shouldn‚Äôt, and that all values passed to certain functions are constant or mutable where need be.&lt;/p&gt;

&lt;p&gt;This is done with symbol information that is collected from prior passes. A symbol table is built up in the semantic pass which contains information like the token name, and whether the variable is mutable or not. It could also contain other information, e.g. in the case of C++, if the symbol is &lt;code class="prettyprint"&gt;extern&lt;/code&gt; or &lt;code class="prettyprint"&gt;static&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id="symbol-tables_3"&gt;Symbol Tables &lt;a class="head_anchor" href="#symbol-tables_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;A symbol table or ‚Äòstab‚Äô is a lookup table for symbols that exist in your program. These exist per scope and contain all of the symbol information for the said scope.&lt;br&gt;
The symbol information is contains properties like the name of the symbol, it could contain the type information too, as well as if the symbol is mutable or not, if it should be externally linked, is it in static memory, etc.&lt;/p&gt;
&lt;h3 id="scope_3"&gt;Scope &lt;a class="head_anchor" href="#scope_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Scope is an important concept in programming languages. Of course your language doesn‚Äôt necessarily have to allow for nested scope, it could all be in one namespace!&lt;br&gt;
Though representing Scope is an interesting problem in compiler design, scope behaves like (or is) a stack data structure in most c-like languages.&lt;br&gt;
Usually, you would push and pop scope, and normally these would control names, e.g. allowing for shadowing of variables:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;{ // push scope
    let x = 3;
    { // push scope
        let x = 4; // OK!
    } // pop scope
} // pop scope
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And this can be represented in a few ways:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;struct Scope {
    Scope* outer;
    SymbolTable symbols;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Somewhat irrelevant, but interesting reading/knowledge: &lt;a href="https://en.wikipedia.org/wiki/Parent_pointer_tree"&gt;Spaghetti stack&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="type-systems_3"&gt;Type Systems &lt;a class="head_anchor" href="#type-systems_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Many of these headings could be their own articles, but I feel like this heading probably takes the cake.&lt;br&gt;
There is a lot of information on type systems out there, and there are many kinds of type systems, and a lot of heated debate about everything. I wont gloss over this topic too much at all, but I will link to this excellent article by &lt;a href="https://blog.steveklabnik.com/posts/2010-07-17-what-to-know-before-debating-type-systems"&gt;Steve Klabnik&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="ownership_3"&gt;Ownership &lt;a class="head_anchor" href="#ownership_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Ownership is a concept that is becoming more and more prevalent in the programming world. Ownership and move semantics are principles in the language &lt;a href="https://en.wikipedia.org/wiki/Rust_(programming_language)"&gt;Rust&lt;/a&gt; ‚Äî and hopefully more to come. There are many forms of static analysis performed on Rust code that checks that input conforms to a set of rules with regards to memory: who owns what memory, when the memory dies, and how many references (or borrows) to these values/memory there are.&lt;/p&gt;

&lt;p&gt;The beauty of Rust is that this is all enforced at compile time, so there is no garbage collection or reference counting forced upon the programmer, these semantics are offset to the type system and can be enforced before the program even exists as a compiled binary.&lt;/p&gt;

&lt;p&gt;I can‚Äôt speak on the internals of how this all works, but I can tell you that it is the work of static analysis and some cool research by the folks at Mozilla and the people behind &lt;a href="https://en.wikipedia.org/wiki/Cyclone_%28programming_language%29"&gt;Cyclone&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="backend_2"&gt;Backend &lt;a class="head_anchor" href="#backend_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/8/85/Hutong_Barren_Wasteland.jpg" alt="an image of a barren wasteland"&gt;&lt;/p&gt;

&lt;p&gt;The final part in our architecture diagram.&lt;/p&gt;

&lt;p&gt;This is where most of the work is done to produce our binary executable. There are a few ways to do this, which we will discuss in the later segments of this article.&lt;/p&gt;

&lt;p&gt;The semantic analysis phase doesn‚Äôt necessarily have to mutate a lot of the information on the tree, and it‚Äôs probably a better idea not to in terms of avoiding some spaghetti mess.&lt;/p&gt;
&lt;h3 id="a-note-on-transpilers_3"&gt;A note on transpilers &lt;a class="head_anchor" href="#a-note-on-transpilers_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Transpilers are another form of compiler, in which the compiler transpiles into another ‚Äòsource level‚Äô language, e.g. you could write something that compiles into C code. I think this is somewhat pointless though if your language doesn‚Äôt have a lot to offer on top of the language its compiling to. It mostly seems to make sense for languages that are relatively high level or the language itself is limited.&lt;br&gt;
A big example for this is JavaScript. TypeScript transpiles into JavaScript to introduce more features to the language, and most importantly a sensible type system with various amounts of static analysis to catch bugs and errors before we encounter them at runtime.&lt;br&gt;
This is relatively important when writing a language like JavaScript where you may not encounter any problems until they occur due to the nature of it being a dynamically typed language.&lt;/p&gt;
&lt;h3 id="llvm_3"&gt;LLVM &lt;a class="head_anchor" href="#llvm_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Many modern compilers will opt for using LLVM as their backend: Rust, Swift, C/C++ (clang), D, Haskell.&lt;br&gt;
This can be considered the ‚Äòeasier route‚Äô, as most of the work is done for you in supporting a wide variety of architectures, and providing an insurmountable level of optimisation.&lt;/p&gt;
&lt;h3 id="generating-assembly_3"&gt;Generating Assembly &lt;a class="head_anchor" href="#generating-assembly_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Generating code directly for a specific architecture, i.e. machine code or assembly is technically the most common route with countless languages opting for this route.&lt;/p&gt;

&lt;p&gt;Go is an example of a modern language that does not take advantage of the LLVM framework (as of writing this). It generates code for a few platforms/architectures: Windows, Linux, and MacOS to name a few. And a fun fact, my language Krug did generate assembly earlier on in the prototype version of the language.&lt;/p&gt;

&lt;p&gt;There are lots of pros and cons to this, though nowadays with technology like LLVM available it‚Äôs silly to generate assembly code yourself as it is unlikely a toy compiler that has it‚Äôs own assembly backend would surpass a production level compilers level of optimisation for one platform let alone many others.&lt;/p&gt;

&lt;p&gt;Regardless, it‚Äôs still a very fun thing to attempt doing. And is especially interesting if you wanted to learn more about programming in assembly. The easiest way to approach this is to walk the AST, or walk the generated IR (if you have one) and ‚Äòemit‚Äô assembly instructions to a file. This is how &lt;a href="https://github.com/rui314/8cc"&gt;8cc&lt;/a&gt; works.&lt;/p&gt;
&lt;h3 id="bytecode-generation_3"&gt;Bytecode Generation &lt;a class="head_anchor" href="#bytecode-generation_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Another option is generating bytecode for some kind of virtual machine or a bytecode interpreter. Java is a prime example of this, in fact the &lt;a href="https://en.wikipedia.org/wiki/Java_virtual_machine"&gt;JVM&lt;/a&gt; has spawned an entire family of languages that generate bytecode for it, e.g. Kotlin.&lt;br&gt;
There are many benefits of generating bytecode, the main reason for Java was for portability. If you can have your virtual machine run anywhere, any code that executes on the virtual machine will run anywhere too. And it‚Äôs a lot simple to make something like an abstract set of bytecode instructions run on machines than it is to target 50 bajillion computer architectures.&lt;/p&gt;

&lt;p&gt;Personally, I prefer to use any LLVM-based compiler I can find in most languages I work with, e.g. C/C++ or D.&lt;/p&gt;
&lt;h3 id="optimisations_3"&gt;Optimisations &lt;a class="head_anchor" href="#optimisations_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Optimisations are key part in the backend of a compiler. They will usually be the larger part of the backend, and there is a lot of research on squeezing out the extra bits of performance with code. If you ever compile some C code and run it with all optimisations on full flex, it can be amazing what kind of madness it can produce. &lt;a href="https://godbolt.org/"&gt;godbolt‚Äôs compiler explorer&lt;/a&gt; is a great tool to look into how existing compilers generate their code, what instructions relate to what source code, as well as you can specify certain levels of optimisations, targets, versions of compilers, etc.&lt;br&gt;
A good start if you are ever writing a compiler is to write simple programs in C and turn off all optimisations, as well as strip the debug symbols, and have a look at what code GCC generates.&lt;/p&gt;
&lt;h3 id="ir_3"&gt;IR &lt;a class="head_anchor" href="#ir_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Having an intermediate representation (IR) is not required, but definitely beneficial. You could generate code from the AST, though it can become quite tedious and messy to do so, as well as it‚Äôs quite difficult to optimise.&lt;/p&gt;

&lt;p&gt;An IR can be thought of as a higher level representation of the code that you are generating for. It must be very accurate to what it represents, and must contain all of the information necessary to generate the code.&lt;/p&gt;

&lt;p&gt;There are certain types of IR, or ‚Äòforms‚Äô you can make with the IR to allow for easier optimisations. One example of this is SSA, or Static Single Assignment, in which every variable is assigned exactly once.&lt;br&gt;
Go builds an SSA based IR before it generates code. LLVM‚Äôs IR is built upon the concept of SSA to provide its optimisations.&lt;/p&gt;

&lt;p&gt;SSA provides a few optimisations by nature, for example constant propagation, dead code elimination, and (a big one) register allocation.&lt;/p&gt;
&lt;h4 id="register-allocation_4"&gt;Register Allocation &lt;a class="head_anchor" href="#register-allocation_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;Register allocation is not a necessity when it comes to generating code. One abstraction we take for granted is that we can define as many variables as required for our programs. In assembly, however, we can either make use of the finite amount of registers [usually 16 to 32] available (and keep track of them in our heads), or we can spill to the stack.&lt;/p&gt;

&lt;p&gt;Register allocation is an attempt to find what variables can go in what registers at what point of time (without overwriting other values). This is much more efficient than spilling to the stack, though can be quite expensive and impossible for a computer to calculate the perfect solution.&lt;br&gt;
A few algorithms for register allocation are: graph colouring, which is as computationally hard problem (NP-complete). Or a linear scan which will scan the variables to determine their liveness ranges - as opposed to graph colouring which requires the code is in graph form to calculate the liveness of variables.&lt;/p&gt;
&lt;h3 id="things-to-consider_3"&gt;Things to consider &lt;a class="head_anchor" href="#things-to-consider_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;There is a vast amount of information on compilers. So much to cover that it would not fit nicely into this article. That being said, I wanted to write up, or at least mention, a few bits and pieces that should be considered for any of your future endeavours.&lt;/p&gt;
&lt;h4 id="a-hrefhttpsenwikipediaorgwikinamemanglingname_4"&gt;
&lt;a href="https://en.wikipedia.org/wiki/Name_mangling"&gt;Name Mangling&lt;/a&gt; &lt;a class="head_anchor" href="#a-hrefhttpsenwikipediaorgwikinamemanglingname_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;If you are generating assembly where there isn‚Äôt really any scope or namespace, you will have an issue with conflicting symbols in a lot of cases. Especially if your language supports function overloading or classes, etc.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;fn main() int {
    let x = 0;
    {
        let x = 0;
        {
            let x = 0;
        }
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For instance, the previous example (if the variables don‚Äôt get optimised out anyway üòâ) you will have to mangle the names of those symbols so that they would not conflict in the generated assembly. Name mangling usually indicates type information too, or it could contain scope information, etc.&lt;/p&gt;
&lt;h4 id="debug-information_4"&gt;Debug Information &lt;a class="head_anchor" href="#debug-information_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;Tools like LLDB usually integrate with standards like &lt;a href="https://en.wikipedia.org/wiki/DWARF"&gt;DWARF&lt;/a&gt;. Another excellent feature of LLVM is that you get some relatively easy integration with the existing GNU debugger tool via. DWARF. Your language would probably need a debugger, it‚Äôs always easiest to use someone else‚Äôs, unless you were to roll your own.&lt;/p&gt;
&lt;h4 id="foreign-function-interface-a-hrefhttpsenwikip_4"&gt;Foreign Function Interface (&lt;a href="https://en.wikipedia.org/wiki/Libffi"&gt;FFI&lt;/a&gt;) &lt;a class="head_anchor" href="#foreign-function-interface-a-hrefhttpsenwikip_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;There is usually no escape from libc, you should probably read up on this and think about how you would incorporate this in your language. How will you hook into C code, or expose your languages code to C?&lt;/p&gt;
&lt;h4 id="linking_4"&gt;Linking &lt;a class="head_anchor" href="#linking_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;Writing your own linker is a task of its own. When your compiler generates code, does it generate a machine code of some sort (i.e. into a &lt;code class="prettyprint"&gt;.s&lt;/code&gt;/&lt;code class="prettyprint"&gt;.asm&lt;/code&gt; file)? Does it write the code directly to an object file? Jonathan Blow‚Äôs programming language &lt;a href="https://www.youtube.com/watch?v=TH9VCN6UkyQ"&gt;Jai&lt;/a&gt; supposedly writes all of the code into a single object file. There are many different approaches to this with varying trade offs.&lt;/p&gt;
&lt;h2 id="a-hrefhttpskruglangorgkruga-compilerasaservic_2"&gt;
&lt;a href="https://krug-lang.org"&gt;KRUG&lt;/a&gt; - Compiler-as-a-Service (CAAS) &lt;a class="head_anchor" href="#a-hrefhttpskruglangorgkruga-compilerasaservic_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Krug is my own programming language. It‚Äôs still under heavy development, and is prone to breaking. There is a demo of it on my YouTube channel &lt;a href="https://www.youtube.com/watch?v=DT6l4T7yzKs"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Krug is written as a REST API service, where each stage that is explained in this article is a route in the API. The compiler itself ‚Äòcaasper‚Äô runs locally on your machine (or on a server if you wanted to), and then the frontends or clients, e.g. ‚Äòkrug‚Äô communicate to and from this compiler. It is what is referred to as a ‚Äòcompiler-as-a-service‚Äô architecture. An architecture that is currently used in Roslyn by Microsoft.&lt;/p&gt;

&lt;p&gt;The compiler phases that have been discussed in this post are cut into API routes, which means that a text editor could request to the Krug server to tokenize a file and get back a response of the tokens that it produced. In addition, all of the static analysis routes are exposes, so tooling becomes a breeze.&lt;/p&gt;

&lt;p&gt;The frontend for the Krug language is implemented in JavaScript, though there will be alternative frontends implemented in Go*, as well as a frontend hopefully written in Krug itself. JavaScript was chosen as it is quite an accessible language and can be downloaded with yarn or npm.&lt;/p&gt;

&lt;p&gt;*The initial frontend was written in Go, and was (unsurprisingly) significantly faster than the JS frontend.&lt;/p&gt;

&lt;p&gt;There are obviously trade offs like latency between sending and receiving files over, as well as a lot of the design of the compiler has to be thought of differently to work in the context of API routes. The source code for Caasper - the compiler itself - can be found &lt;a href="https://github.com/hugobrains/caasper/"&gt;here&lt;/a&gt;.&lt;br&gt;
In addition, a prototype of Krug is available on my personal GitHub &lt;a href="http://github.com/felixangell/krug/"&gt;here&lt;/a&gt;, it‚Äôs written in D and compiles down to LLVM.&lt;/p&gt;

&lt;p&gt;You can read the (work in progress) Krug tutorial &lt;a href="https://github.com/hugobrains/caasper/blob/master/docs/tutorial.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="hello_1"&gt;Hello! &lt;a class="head_anchor" href="#hello_1"&gt;#&lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Thanks for making it this far. I hope you enjoyed the article. Feel free to &lt;a href="https://twitter.com/Felix_Angell"&gt;follow me&lt;/a&gt; on Twitter.&lt;/p&gt;

&lt;p&gt;I will likely be updating this article as the time passes with more information or edits here and there, and I‚Äôll likely Tweet when I do so.&lt;/p&gt;
&lt;h2 id="further-reading_2"&gt;Further Reading &lt;a class="head_anchor" href="#further-reading_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://compilers.iecc.com/crenshaw/"&gt;Jack Crenshaw&lt;/a&gt; - my personal gateway into the realm of programming language implementation&lt;/li&gt;
&lt;li&gt;&lt;a href="https://craftinginterpreters.com/"&gt;Crafting Interpreters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://blog.felixangell.com/an-introduction-to-llvm-in-go"&gt;An Introduction to LLVM (with Go)&lt;/a&gt; - me!&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/PL/0"&gt;PL/0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The Dragon Book - a classic book that has &lt;u&gt;everything&lt;/u&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rui314/8cc"&gt;8cc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry>
    <id>tag:blog.felixangell.com,2014:Post/an-introduction-to-llvm-in-go</id>
    <published>2016-12-03T13:33:50-08:00</published>
    <updated>2016-12-03T13:33:50-08:00</updated>
    <link rel="alternate" type="text/html" href="http://blog.felixangell.com/an-introduction-to-llvm-in-go"/>
    <title>An introduction to LLVM in Go</title>
    <content type="html">&lt;p&gt;&lt;u&gt;&lt;strong&gt;Hacker News Dicussion&lt;/strong&gt;&lt;br&gt;
&lt;a href="https://news.ycombinator.com/item?id=11278551"&gt;Article discussion on Hacker News&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;
&lt;h3 id="translations_3"&gt;Translations &lt;a class="head_anchor" href="#translations_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Some translations of this article:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://postd.cc/an-introduction-to-llvm-in-go/"&gt;Japanese&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.opensourceinitiative.net/edu/llvm-intro/"&gt;Russian&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="introduction_2"&gt;Introduction &lt;a class="head_anchor" href="#introduction_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;LLVM is an infrastructure for creating compilers. It was initially created by Chris Lattner in 2000, and released in 2003. Since then it has evolved into an umbrella project that has a wide array of tools such as the LLVM Linker &lt;code class="prettyprint"&gt;lld&lt;/code&gt;, LLVM Debugger &lt;code class="prettyprint"&gt;lldb&lt;/code&gt;, and so on.&lt;/p&gt;

&lt;p&gt;The banner feature of LLVM is its intermediate representation, commonly referred to as the &lt;code class="prettyprint"&gt;LLVM IR&lt;/code&gt;. The idea of LLVM is that you can compile down to this IR, and then this IR can be JIT compiled, interpreted, or compiled into native assembly for the machine it‚Äôs running on. The primary target of this IR is compilers, in fact there are many compilers out there that use LLVM: clang and clang++ for C and C++ respectively, &lt;code class="prettyprint"&gt;ldc2&lt;/code&gt; for the D programming language, the Rust language, Swift, etc. There are even projects like &lt;a href="https://github.com/kripken/emscripten"&gt;emscripten&lt;/a&gt;, which can compile LLVM BC (LLVM bitcode) into javascript to be executed in the browser. &lt;/p&gt;

&lt;p&gt;Typically in compiler design you would have to worry about register allocation, generating code for different architectures, and also producing good code that is well optimized. The beauty of LLVM is that it does this for you. LLVM features a vast collection of optimisations, can target a variety of architectures, and has a nice API that makes code generation a whole lot more simpler.&lt;/p&gt;
&lt;h3 id="llvm-ir_3"&gt;LLVM IR &lt;a class="head_anchor" href="#llvm-ir_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Now lets take a swift look at the LLVM IR. If you take your average C program and run it through &lt;code class="prettyprint"&gt;clang&lt;/code&gt; with the &lt;code class="prettyprint"&gt;-emit-llvm&lt;/code&gt; and &lt;code class="prettyprint"&gt;-S&lt;/code&gt; flag, it will produce an &lt;code class="prettyprint"&gt;.ll&lt;/code&gt; file. This file extension means that it‚Äôs LLVM IR.&lt;/p&gt;

&lt;p&gt;Here‚Äôs the C code I‚Äôm going to compile into LLVM IR:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;int main() {
  int a = 32;
  int b = 16;
  return a + b;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I‚Äôve ran it through clang, specifying to not optimize anything: &lt;code class="prettyprint"&gt;clang test.c -S -emit-llvm -O0&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;define i32 @main() #0 {
  %1 = alloca i32, align 4
  %a = alloca i32, align 4
  %b = alloca i32, align 4
  store i32 0, i32* %1
  store i32 32, i32* %a, align 4
  store i32 16, i32* %b, align 4
  %2 = load i32, i32* %a, align 4
  %3 = load i32, i32* %b, align 4
  %4 = add nsw i32 %2, %3
  ret i32 %4
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I‚Äôve omitted a lot of the excess code for simplicity sake. If you have a look at the IR, it looks very much like a more verbose, readable assembly. Something you may note is that the IR is strongly typed. There are type annotations everywhere, instructions, values, functions, etc.&lt;/p&gt;

&lt;p&gt;Let‚Äôs step through this IR and try get a grasp of what is going on. First off we have a function with a syntax very much like a C-style function with the brace, type, name and the parenthesis for arguments.&lt;/p&gt;

&lt;p&gt;In our function we have a bunch of values and instructions. In the IR we see 5 instructions, &lt;code class="prettyprint"&gt;alloca&lt;/code&gt;, &lt;code class="prettyprint"&gt;store&lt;/code&gt;, &lt;code class="prettyprint"&gt;load&lt;/code&gt;, &lt;code class="prettyprint"&gt;add&lt;/code&gt;, and &lt;code class="prettyprint"&gt;ret&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Let‚Äôs dissect the IR part-by-part to help understand how this works. Note that I‚Äôve ignored a few things here, namely the alignment, and the &lt;code class="prettyprint"&gt;nsw&lt;/code&gt; flags. You can learn more about those in the LLVM documentation, I‚Äôll just be explaining the underlying semantics.&lt;/p&gt;
&lt;h4 id="locals_4"&gt;Locals &lt;a class="head_anchor" href="#locals_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;Before we get onto the instructions, you should know what a local is. Locals are like variables. They are denoted with a percent symbol &lt;code class="prettyprint"&gt;%&lt;/code&gt;. As the name suggests, they are local to the function they are defined in. This means that they cannot be modified/referenced outside of the function that declares them.&lt;/p&gt;
&lt;h4 id="code-classprettyprintallocacode_4"&gt;
&lt;code class="prettyprint"&gt;alloca&lt;/code&gt; &lt;a class="head_anchor" href="#code-classprettyprintallocacode_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;This instruction will allocate memory in the stack frame. This memory is freed when the function is returned. The instruction returns a value, this is why we assign it to &lt;code class="prettyprint"&gt;%a&lt;/code&gt;, etc. The value it returns is a pointer to the memory that is allocated. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;%a = alloca i32, align 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This instruction allocates space for a 32 bit signed integer on the stack. The pointer is stored in the local &lt;code class="prettyprint"&gt;a&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id="code-classprettyprintstorecode_4"&gt;
&lt;code class="prettyprint"&gt;store&lt;/code&gt; &lt;a class="head_anchor" href="#code-classprettyprintstorecode_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;The store instruction will change the value at the given pointer to contain the given value. Here‚Äôs an example to simplify the explanation:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;store i32 32, i32* %a, align 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we tell LLVM to store the value 32 of type &lt;code class="prettyprint"&gt;i32&lt;/code&gt; into the local &lt;code class="prettyprint"&gt;a&lt;/code&gt; of the type &lt;code class="prettyprint"&gt;i32*&lt;/code&gt; (a pointer to an i32). This instruction returns void, i.e. it returns nothing and cannot be assigned to a local.&lt;/p&gt;
&lt;h4 id="code-classprettyprintloadcode_4"&gt;
&lt;code class="prettyprint"&gt;load&lt;/code&gt; &lt;a class="head_anchor" href="#code-classprettyprintloadcode_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;Finally, the &lt;code class="prettyprint"&gt;load&lt;/code&gt; instruction. This instruction will return the value at the given memory address:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;%2 = load i32, i32* %a, align 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the example above, we load a value of type &lt;code class="prettyprint"&gt;i32&lt;/code&gt; from the memory address &lt;code class="prettyprint"&gt;a&lt;/code&gt; (which is a pointer to an &lt;code class="prettyprint"&gt;i32&lt;/code&gt;). This value is stored into the local &lt;code class="prettyprint"&gt;2&lt;/code&gt;. We have to load values because we can‚Äôt just dereference &lt;/p&gt;

&lt;p&gt;We now know what the instructions mean, so hopefully you should be able to read and understand more than half of the IR above. As for the rest of the instructions, they should be relatively straight-forward. &lt;code class="prettyprint"&gt;add&lt;/code&gt; will perform addition on the given values and return the result. The &lt;code class="prettyprint"&gt;ret&lt;/code&gt; instruction specifies the value to return from the function.&lt;/p&gt;
&lt;h3 id="llvm-api_3"&gt;LLVM API &lt;a class="head_anchor" href="#llvm-api_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;LLVM provides an API for building this IR. The initial API is in C++, though there are bindings to a variety of languages from Lua, to OCaml, C, Go, and many more. &lt;/p&gt;

&lt;p&gt;In this article, I‚Äôll be using the Go bindings. Though before we start building some IR, we need to know and understand a few details:&lt;/p&gt;
&lt;h4 id="modules_4"&gt;Modules &lt;a class="head_anchor" href="#modules_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;A module is a group of definitions and declarations. This is the container, and we must make one. Typically modules are created per-file, so in our C example, that file was a module.&lt;/p&gt;

&lt;p&gt;We create a module like so. We pass a string as the name of the module, we‚Äôre going to call ours ‚Äúmain‚Äù as it‚Äôs the main module:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;module := llvm.NewModule("main")
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id="types_4"&gt;Types &lt;a class="head_anchor" href="#types_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;LLVM provides a wide variety of types, from primitive types like bytes, integers, floating point, to more complex types like Structures, Arrays, and Function Types.&lt;/p&gt;

&lt;p&gt;There are some built in types, in the format of &lt;code class="prettyprint"&gt;TypeWidthType()&lt;/code&gt;, so for example &lt;code class="prettyprint"&gt;Int16Type&lt;/code&gt; is an integer with a width of 16 bits.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;foo := llvm.Int16Type()
bar := llvm.Int32Type()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can also specify arbitrary bit-widths:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;fupa := llvm.IntType(32)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;An array is like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;ages := llvm.ArrayType(llvm.Int32Type(), 16)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is an array of 16 32-bit integers.&lt;/p&gt;
&lt;h4 id="values_4"&gt;Values &lt;a class="head_anchor" href="#values_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;LLVM values can be returned from instructions, though they can also be constants, functions, globals, ‚Ä¶&lt;/p&gt;

&lt;p&gt;Below we create a constant integer of type &lt;code class="prettyprint"&gt;i32&lt;/code&gt;, with the value &lt;code class="prettyprint"&gt;666&lt;/code&gt;. The boolean parameter at the end is whether to sign extend.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;foo := llvm.ConstInt(llvm.Int32Type(), 666, false)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can create floating point constants:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;bar := llvm.ConstFloat(llvm.FloatType(), 32.5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And we can assign these values to variables, or pass them to functions, and so on. Here we create an add instruction that adds two constant values:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;a := llvm.ConstInt(llvm.Int32Type(), 12)
b := llvm.ConstInt(llvm.Int32Type(), 24)
c := llvm.ConstAdd(a, b)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id="basic-blocks_4"&gt;Basic Blocks &lt;a class="head_anchor" href="#basic-blocks_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;This is slightly different to how you may expect. In assembly, we use labels for functions, and control flow. LLVM is very similar to this, though we have an explicit syntax for functions. But how do we control the flow of our program? We use basic blocks. So the IR would look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;define i32 @main() {
entry:
    ...
0:
    ...
1:
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We have our main function, and inside of this function we have three basic blocks. The entry block, and then the 0 and 1 block. You can have as many basic blocks as you want. They are used for things like jumping around, for instance looping, if statements, and so on.&lt;/p&gt;

&lt;p&gt;In the Go bindings for LLVM, we define a basic block like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;llvm.AddBasicBlock(context, "entry")
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where the context is the function that we want to add the block to. This is &lt;u&gt;not&lt;/u&gt; a function type. We‚Äôll discuss this later, though.&lt;/p&gt;
&lt;h4 id="ir-builder_4"&gt;IR Builder &lt;a class="head_anchor" href="#ir-builder_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;The IR Builder will create our IR for us. We feed it values, instructions, etc. and it will join them all together. The key part of the builder is that we can use it to reposition where we build, and append instructions in different places.&lt;/p&gt;

&lt;p&gt;We can use this builder to append instructions to our module. Below we setup a builder, make a function and entry block, then append some simple instructions to store a constant:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;builder := llvm.NewBuilder()
// create a function "main"
// create a block "entry"

foo := builder.CreateAlloca(llvm.Int32Type(), "foo")
builder.CreateStore(foo, llvm.ConstInt(llvm.Int32Type(), 12, false))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This produces IR like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;define i32 @main() {
entry:
    %foo = alloca i32
    store i32 12, i32* %foo
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id="functions_4"&gt;Functions &lt;a class="head_anchor" href="#functions_4"&gt;#&lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;Functions are a type in LLVM. We need to specify a few things when we define this function type: the return type, parameter types, and if the function is variadic, i.e. if it takes a variable amount of arguments.&lt;/p&gt;

&lt;p&gt;Here‚Äôs our main function as we‚Äôve seen it thus far:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;main := llvm.FunctionType(llvm.Int32Type(), []llvm.Type{}, false)
llvm.AddFunction(mod, "main", main)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first parameter is the return type, so a 32 bit integer. Our function takes no parameters, so we just pass an empty type array. And the function is not variadic, so we pass false in the for the last argument. Easy right?&lt;/p&gt;

&lt;p&gt;The AddFunction will add the function to the given module as the given name. We can then reference this later (it‚Äôs stored in a key/value map) like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;mainFunc := mod.NamedFunction("main")
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will lookup the function in the module.&lt;/p&gt;

&lt;p&gt;Now we can piece together everything we‚Äôve learned so far:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;// setup our builder and module
builder := llvm.NewBuilder()
mod := llvm.NewModule("my_module")

// create our function prologue
main := llvm.FunctionType(llvm.Int32Type(), []llvm.Type{}, false)
llvm.AddFunction(mod, "main", main)
block := llvm.AddBasicBlock(mod.NamedFunction("main"), "entry")

// note that we've set a function and need to tell
// the builder where to insert things to
builder.SetInsertPoint(block, block.FirstInstruction())

// int a = 32
a := builder.CreateAlloca(llvm.Int32Type(), "a")
builder.CreateStore(llvm.ConstInt(llvm.Int32Type(), 32, false), a)

// int b = 16
b := builder.CreateAlloca(llvm.Int32Type(), "b")
builder.CreateStore(llvm.ConstInt(llvm.Int32Type(), 16, false), b)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So far so good, but because an &lt;code class="prettyprint"&gt;alloca&lt;/code&gt; returns a pointer, we can‚Äôt just add them together. We have to generate some loads to ‚Äúdereference‚Äù our pointer.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;aVal := builder.CreateLoad(a, "a_val")
bVal := builder.CreateLoad(b, "b_val")
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then the arithmetic part. We‚Äôll be doing &lt;code class="prettyprint"&gt;a + b&lt;/code&gt;, this is straight-forward as we just need to create an add instruction:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;result := builder.CreateAdd(aVal, bVal, "ab_value")
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we need to return this since our function returns an &lt;code class="prettyprint"&gt;i32&lt;/code&gt;. &lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;builder.CreateRet(result)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that is it! But how do we execute this? We have a few choices, we can either:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use LLVM‚Äôs JIT/execution engine&lt;/li&gt;
&lt;li&gt;Translate into IR -&amp;gt; BitCode -&amp;gt; Assembly -&amp;gt; Object -&amp;gt; Executable&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Because the first option is a little more concise to fit into the executable, I‚Äôm going for that route. I‚Äôll leave it as an exercise to the reader to do the second route. If you create an executable, if you check the status code after running it, it should be the &lt;code class="prettyprint"&gt;48&lt;/code&gt; which is the result. To do this in Bash, echo out &lt;code class="prettyprint"&gt;$?&lt;/code&gt; environmental variable:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;$ ./a.out
$ echo $?
$ 48
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you want to print this to standard out, you will have to define the &lt;code class="prettyprint"&gt;printf&lt;/code&gt; function, &lt;code class="prettyprint"&gt;putch&lt;/code&gt; or some equivalent. Hopefully this tutorial provides you with enough to do this. If you get stuck (shameless plug), I‚Äôm working on a language called Ark that is built on top of LLVM and is written in Go. &lt;a href="https://github.com/ark-lang/ark/blob/master/src/codegen/LLVMCodegen/codegen.go"&gt;You can check out our code generator here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There is also documentation availible on the LLVM bindings &lt;a href="https://godoc.org/llvm.org/llvm/bindings/go/llvm"&gt;here&lt;/a&gt;. This has almost everything you need to know.&lt;/p&gt;

&lt;p&gt;As well as the &lt;a href="http://llvm.org/docs/LangRef.html"&gt;LLVM specification&lt;/a&gt;, which covers everything in detail. This includes instructions, intrinsics, attributes, and everything else.&lt;/p&gt;
&lt;h3 id="running-our-code_3"&gt;Running our code! &lt;a class="head_anchor" href="#running-our-code_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Enough rambling, lets get to it. Here‚Äôs an overview of what this section involves:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Verifying our module&lt;/li&gt;
&lt;li&gt;Initializing the execution engine&lt;/li&gt;
&lt;li&gt;Setting up our function call and executing it!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;First let‚Äôs verify our module is correct. &lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;if ok := llvm.VerifyModule(mod, llvm.ReturnStatusAction); ok != nil {
    fmt.Println(ok.Error())
    // ideally you would dump and exit, but hey ho
}
mod.Dump()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will print out the error if our module is invalid. An invalid module could be caused by a variety of things, though malformed IR is the most likely cause. The &lt;code class="prettyprint"&gt;mod.Dump()&lt;/code&gt; call will dump the module IR to the standard out.&lt;/p&gt;

&lt;p&gt;Now to initialize an execution engine:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;engine, err := llvm.NewExecutionEngine(mod)
if err != nil {
    fmt.Println(err.Error())
    // exit...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And finally, running our function and printing the result to stdout. We pass an empty array of GenericValues since our function takes no arguments:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;funcResult := engine.RunFunction(mod.NamedFunction("main"), []llvm.GenericValue{})
fmt.Printf("%d\n", funcResult.Int(false))
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="building_3"&gt;Building &lt;a class="head_anchor" href="#building_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;You need to have LLVM installed. Luckily for me this is as simple as:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;$ pacman -S llvm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you are on Windows, this may be trickier. On any other Linux distribution, search for llvm in your package manager. On Mac you can use Homebrew.&lt;/p&gt;

&lt;p&gt;And then we install the go bindings. The release variable is 362, though if you are using say llvm 3.7.0, this should be 370, etc. The below will clone the LLVM repository into the GOPATH, then build and install the bindings.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;$ release=RELEASE_362
$ svn co https://llvm.org/svn/llvm-project/llvm/tags/$release/final $GOPATH/src/llvm.org/llvm
$ cd $GOPATH/src/llvm.org/llvm/bindings/go
$ ./build.sh
$ go install llvm.org/llvm/bindings/go/llvm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now in the go file, make sure you &lt;code class="prettyprint"&gt;import "llvm.org/llvm/bindings/go/llvm"&lt;/code&gt;. Once this is done, you can run your go file and it should print out the result:&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/img/Screenshot-from-2016-03-13-17-42-03.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;Done! I hope you learned new things. And hopefully you can see how this can be used to write a programming language. The next step from here would be to check out the Kaleidoscope tutorial, or experiment and try implement your own thing.&lt;/p&gt;

&lt;p&gt;If you liked this article, tweet me &lt;a href="http://twitter.com/felix_angell"&gt;@felix_angell&lt;/a&gt;!&lt;br&gt;
Thanks for reading!&lt;/p&gt;
&lt;h3 id="full-code_3"&gt;Full Code &lt;a class="head_anchor" href="#full-code_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;package main

import (
    "fmt"
    "llvm.org/llvm/bindings/go/llvm"
)

func main() {
    // setup our builder and module
    builder := llvm.NewBuilder()
    mod := llvm.NewModule("my_module")

    // create our function prologue
    main := llvm.FunctionType(llvm.Int32Type(), []llvm.Type{}, false)
    llvm.AddFunction(mod, "main", main)
    block := llvm.AddBasicBlock(mod.NamedFunction("main"), "entry")
    builder.SetInsertPoint(block, block.FirstInstruction())

    // int a = 32
    a := builder.CreateAlloca(llvm.Int32Type(), "a")
    builder.CreateStore(llvm.ConstInt(llvm.Int32Type(), 32, false), a)

    // int b = 16
    b := builder.CreateAlloca(llvm.Int32Type(), "b")
    builder.CreateStore(llvm.ConstInt(llvm.Int32Type(), 16, false), b)

    // return a + b
    bVal := builder.CreateLoad(b, "b_val")
    aVal := builder.CreateLoad(a, "a_val")
    result := builder.CreateAdd(aVal, bVal, "ab_val")
    builder.CreateRet(result)

    // verify it's all good
    if ok := llvm.VerifyModule(mod, llvm.ReturnStatusAction); ok != nil {
        fmt.Println(ok.Error())
    }
    mod.Dump()

    // create our exe engine
    engine, err := llvm.NewExecutionEngine(mod)
    if err != nil {
        fmt.Println(err.Error())
    }

    // run the function!
    funcResult := engine.RunFunction(mod.NamedFunction("main"), []llvm.GenericValue{})
    fmt.Printf("%d\n", funcResult.Int(false))
}
&lt;/code&gt;&lt;/pre&gt;
</content>
  </entry>
  <entry>
    <id>tag:blog.felixangell.com,2014:Post/virtual-machine-in-c</id>
    <published>2015-11-15T14:27:07-08:00</published>
    <updated>2015-11-15T14:27:07-08:00</updated>
    <link rel="alternate" type="text/html" href="http://blog.felixangell.com/virtual-machine-in-c"/>
    <title>Virtual machine in C</title>
    <content type="html">&lt;p&gt;&lt;u&gt;&lt;strong&gt;Hacker News Dicussion&lt;/strong&gt;&lt;br&gt;
&lt;a href="https://news.ycombinator.com/item?id=9762054"&gt;Article discussion on Hacker News&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;
&lt;h2 id="introduction_2"&gt;Introduction &lt;a class="head_anchor" href="#introduction_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Here‚Äôs the GitHub to show what we‚Äôll be making. You can also compare your code to this repository in case you have any errors: &lt;a href="http://www.github.com/felixangell/mac"&gt;GitHub Repository&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I felt like writing an article about building your very own virtual machine in the C programming language. I love working on lower level applications e.g. compilers, interpreters, parsers, virtual machines, etc. So I thought I‚Äôd write this article as learning how virtual machines work is a great way to introduce yourself into the general realm of lower level programming!&lt;/p&gt;
&lt;h2 id="prerequisites-amp-notices_2"&gt;Prerequisites &amp;amp; Notices &lt;a class="head_anchor" href="#prerequisites-amp-notices_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;There are a few things that you need before we can continue:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GCC/Clang/.. ‚Äî I‚Äôm using clang, but you can use any modern compiler;&lt;/li&gt;
&lt;li&gt;Text Editor ‚Äî I would suggest a text editor over an IDE (when writing C), I‚Äôll be using Emacs;&lt;/li&gt;
&lt;li&gt;Basic programming knowledge ‚Äî Just the basics: variables, flow control, functions, structures, etc; and&lt;/li&gt;
&lt;li&gt;GNU Make ‚Äî A build system so we aren‚Äôt writing the same commands in the terminal over and over to compile our code&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="why-should-i-write-a-virtual-machine_2"&gt;Why should I write a Virtual Machine? &lt;a class="head_anchor" href="#why-should-i-write-a-virtual-machine_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Here are some reasons why &lt;strong&gt;you&lt;/strong&gt; should write a virtual machine:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;You want a deeper understanding of how computers work. This article will help you understand what your computer does at a lower level, a virtual machine provides a nice simpler layer of abstraction. And there‚Äôs no better way to learn than build one, ey? &lt;/li&gt;
&lt;li&gt;You just want to learn about virtual machines because it‚Äôs fun.&lt;/li&gt;
&lt;li&gt;You want to learn more about how some programming languages work. For instance, various languages nowadays target virtual machines - usually written specifically for the language. Examples include the JVM, Lua‚Äôs VM, Facebook‚Äôs Hip-Hop VM (PHP/Hack), etc. There‚Äôs also quite a large abstraction, from say a C++ program to assembly for your machine. When you think about it, we take a lot for granted when we write our programs in our fancy OOP paradigm language with garbage collection and all these nice features.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="instruction-set_3"&gt;Instruction Set &lt;a class="head_anchor" href="#instruction-set_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;We‚Äôll be implementing our own instruction set, it will be relatively simple. I‚Äôll briefly cover instructions like moving values from registers, or jumping to other instructions, but hopefully you‚Äôll figure this out after you‚Äôve read the article.&lt;/p&gt;

&lt;p&gt;Our virtual machine will have a set of register: &lt;code class="prettyprint"&gt;A&lt;/code&gt;, &lt;code class="prettyprint"&gt;B&lt;/code&gt;, &lt;code class="prettyprint"&gt;C&lt;/code&gt;, &lt;code class="prettyprint"&gt;D&lt;/code&gt;, &lt;code class="prettyprint"&gt;E&lt;/code&gt;, and &lt;code class="prettyprint"&gt;F&lt;/code&gt;. These are general purpose registers, which means that they can be used for storing anything. This is as opposed to say special purpose registers, for example on x86, e.g: &lt;code class="prettyprint"&gt;ip&lt;/code&gt;, &lt;code class="prettyprint"&gt;flag&lt;/code&gt;, &lt;code class="prettyprint"&gt;ds&lt;/code&gt;, ‚Ä¶ &lt;/p&gt;

&lt;p&gt;A program will be a read-only sequence of instructions. The virtual machine is a stack-based virtual machine, which means that it has a stack we can push and pop values to, and a few registers we can use too. These are also a lot more simpler to implement than a register-based virtual machine.&lt;/p&gt;

&lt;p&gt;Without further ado, here‚Äôs an example of the instruction set we‚Äôre going to be implementing in action. The semi-colons are comments on what the line will do.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;PSH 5       ; pushes 5 to the stack
PSH 10      ; pushes 10 to the stack
ADD         ; pops two values on top of the stack, adds them pushes to stack
POP         ; pops the value on the stack, will also print it for debugging
SET A 0     ; sets register A to 0
HLT         ; stop the program
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That‚Äôs our instruction set, note that the POP instruction will print the instruction we popped, this is more of a debugging thing (ADD will push a result to the stack, so we can POP the value from the stack to verify it is there). &lt;br&gt;
I‚Äôve also included a SET instruction, this is so you understand how registers can be accessed and written to. You can also try your hand at implementing instructions like &lt;code class="prettyprint"&gt;MOV A, B&lt;/code&gt; (move the value A to B). &lt;code class="prettyprint"&gt;HLT&lt;/code&gt; is the instruction to show we‚Äôve finished executing the program.&lt;/p&gt;
&lt;h2 id="how-does-a-virtual-machine-work_2"&gt;How does a Virtual Machine work? &lt;a class="head_anchor" href="#how-does-a-virtual-machine-work_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Virtual Machines are more simple than you think, they follow a simple pattern, the ‚Äúinstruction cycle‚Äù, which is: fetch; decode; and execute.&lt;br&gt;
First we fetch the next instruction in the instruction list or code, we then decode the instruction and execute the decoded instruction.&lt;/p&gt;
&lt;h2 id="project-structure_2"&gt;Project Structure &lt;a class="head_anchor" href="#project-structure_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Before we start programming, we need to set-up our project. We need a folder where our project will be located, I like to keep my projects under &lt;code class="prettyprint"&gt;~/dev&lt;/code&gt;. Here‚Äôs how we would set up our project in the terminal. This is assuming you already have a &lt;code class="prettyprint"&gt;~/dev/&lt;/code&gt; directory, but you can &lt;code class="prettyprint"&gt;cd&lt;/code&gt; into anywhere you want your project to be.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;$ cd ~/dev/
$ mkdir mac
$ cd mac
$ mkdir src
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Above we &lt;code class="prettyprint"&gt;cd&lt;/code&gt; into our &lt;code class="prettyprint"&gt;~/dev&lt;/code&gt; directory, or wherever you want your project to be, we make a directory (I‚Äôm calling this VM ‚Äúmac‚Äù). We then &lt;code class="prettyprint"&gt;cd&lt;/code&gt; into that directory and make our &lt;code class="prettyprint"&gt;src&lt;/code&gt; directory, which is where our code will be located.&lt;/p&gt;
&lt;h2 id="makefile_2"&gt;Makefile &lt;a class="head_anchor" href="#makefile_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Our makefile is relatively straight-forward, we won‚Äôt need to separate anything into multiple files, and we won‚Äôt be including anything so we just need to compile the file with some flags:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-makefile"&gt;SRC_FILES = main.c
CC_FLAGS = -Wall -Wextra -g -std=c11
CC = clang

all:
    ${CC} ${SRC_FILES} ${CC_FLAGS} -o mac
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That should suffice for now, you can always improve it later on, but as long as it does the job, we should be fine.&lt;/p&gt;
&lt;h2 id="program-instructions_2"&gt;Program Instructions &lt;a class="head_anchor" href="#program-instructions_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Now for the Virtual Machines code. First we need to define the instructions for our program. For this, we can just use an &lt;code class="prettyprint"&gt;enum&lt;/code&gt;, since our instructions are basically numbers from 0 - X.&lt;br&gt;
In fact, an assembler program will take your assembly files and (sort of) translate all of the ops into their number counterparts. For example, if you wrote an assembler for mac, it would translate all &lt;code class="prettyprint"&gt;MOV&lt;/code&gt; ops into the number &lt;code class="prettyprint"&gt;0&lt;/code&gt;, and so on.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;typedef enum {
    PSH,
    ADD,
    POP,
    SET,
    HLT
} InstructionSet;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can store a test program as an array. So for a test, we‚Äôll write a simple program to add the values &lt;code class="prettyprint"&gt;5&lt;/code&gt; and &lt;code class="prettyprint"&gt;6&lt;/code&gt;, then print them out.&lt;/p&gt;

&lt;p&gt;Note: When I say print them out, really I‚Äôll just make it so that when we call ‚Äúpop‚Äù our virtual machine will &lt;code class="prettyprint"&gt;printf&lt;/code&gt; the value that we pop. In reality you wouldn‚Äôt want to do this unless you‚Äôre debugging or something. &lt;/p&gt;

&lt;p&gt;The instructions should be stored as an array, I‚Äôll define it somewhere at the top of the document; you could probably throw it in a header file. Here‚Äôs our test program:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;const int program[] = {
    PSH, 5,
    PSH, 6,
    ADD,
    POP,
    HLT
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above program will push &lt;code class="prettyprint"&gt;5&lt;/code&gt; and &lt;code class="prettyprint"&gt;6&lt;/code&gt; to the stack, execute the add instruction which will pop the two values that are on the stack, add them together and push the result back on the stack. We then pop the result since our pop instruction will print the value (for debugging purposes). &lt;/p&gt;

&lt;p&gt;Finally, the &lt;code class="prettyprint"&gt;HLT&lt;/code&gt; instruction means terminate the program. This is used so that if we had control flow we can terminate the program whenever. Our virtual machine will terminate itself naturally if we had no instructions left, though.&lt;/p&gt;

&lt;p&gt;Now we have to implement the instruction cycle (fetch, decode, execute). Technically we don‚Äôt really have to decode anything. This will make more sense later.&lt;/p&gt;
&lt;h2 id="fetching-the-current-instruction_2"&gt;Fetching the current instruction &lt;a class="head_anchor" href="#fetching-the-current-instruction_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Because we have stored our program as an array, it‚Äôs simple to fetch the current instruction. A virtual machine has a counter, typically called a Program Counter, Instruction Pointer, ‚Ä¶ these names are synonymous and your choice is personal preference. Usually they are shortened to PC or IP respectively.&lt;/p&gt;

&lt;p&gt;If you remember before, I said that we would store the program counter as a register‚Ä¶ we will do that, but later on. For now, we‚Äôll just create a variable at the top of our code called &lt;code class="prettyprint"&gt;ip&lt;/code&gt;, and set that to &lt;code class="prettyprint"&gt;0&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;int ip = 0;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This &lt;code class="prettyprint"&gt;ip&lt;/code&gt; stands for instruction pointer. The program itself is stored as an array of integers. The &lt;code class="prettyprint"&gt;ip&lt;/code&gt; variable serves as an index in the array as to which instruction is currently being executed.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;int ip = 0;

int main() {
    int instr = program[ip];
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we were to printf the &lt;code class="prettyprint"&gt;instr&lt;/code&gt; variable, it should give us &lt;code class="prettyprint"&gt;PSH&lt;/code&gt; (or &lt;code class="prettyprint"&gt;0&lt;/code&gt;). We can write this as a fetch function like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;int fetch() {
    return program[ip];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function will return the current instruction when called. So, what if we want the next instruction? We just increment the instruction pointer:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;int main() {
    int x = fetch(); // PSH
    ip++; // increment instruction pointer
    int y = fetch(); // 5
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So how do we automate this? Well we know that a program runs until it is halted via the &lt;code class="prettyprint"&gt;HLT&lt;/code&gt; instruction. So we just have an infinite loop that will keep looping until the current instruction is &lt;code class="prettyprint"&gt;HLT&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;#include &amp;lt;stdbool.h&amp;gt; 

bool running = true;

int main() {
    while (running) {
       int x = fetch();
       if (x == HLT) running = false;
       ip++;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will work perfectly fine, but it‚Äôs kind of messy. What we‚Äôre doing is looping through each instruction, checking if the value of that instruction is &lt;code class="prettyprint"&gt;HLT&lt;/code&gt;, if it is then stop the loop, otherwise eat the instruction and repeat.&lt;/p&gt;
&lt;h2 id="evaluating-an-instruction_2"&gt;Evaluating an instruction &lt;a class="head_anchor" href="#evaluating-an-instruction_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;So this is the gist of our Virtual Machine, but we can do better. A virtual machine is so simple that you can write a huge switch statement. In fact, this is usually the best way to do it in terms of speed, as opposed to say a HashMap for all the instructions and some abstract class or interface with an &lt;code class="prettyprint"&gt;execute&lt;/code&gt; method.&lt;/p&gt;

&lt;p&gt;Each case in the switch statement would be an instruction that we defined in our enum. The eval function will take a single parameter, which is the instruction to evaluate. We won‚Äôt do any of the instruction pointer increments in this function unless we‚Äôre consuming operands.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;void eval(int instr) {
    switch (instr) {
    case HLT:
        running = false;
        break;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let‚Äôs add this back into the main loop of the virtual machine:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;bool running = true;
int ip = 0;

// instruction enum
// eval function
// fetch function

int main() {
    while (running) {
        eval(fetch());
        ip++; // increment the ip every iteration
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="the-stack_2"&gt;The stack! &lt;a class="head_anchor" href="#the-stack_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Great, that should work perfectly. Now before we add the other instructions, we need a stack. The stack is a very simple data structure. We‚Äôll be using an array for this rather than a linked list. Because our stack is a fixed size, we don‚Äôt have to worry about resizing/copying. And it‚Äôs probably better in terms of cache efficiency to use an array rather than a linked list!&lt;/p&gt;

&lt;p&gt;Similarly to how we have an &lt;code class="prettyprint"&gt;ip&lt;/code&gt; that indexes the program array, we need a stack pointer (&lt;code class="prettyprint"&gt;sp&lt;/code&gt;) to show where we are in the stack array.&lt;/p&gt;

&lt;p&gt;Here‚Äôs a little visualisation of our stack data structure:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;[] // empty

PSH 5 // put 5 on **top** of the stack
[5]

PSH 6 // 6 on top of the stack
[5, 6]

POP // pop the 6 off the top
[5]

POP // pop the 5
[] // empty

PSH 6 // push a 6...
[6]

PSH 5 // etc..
[6, 5]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let‚Äôs break down our program in terms of the stack:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;PSH, 5,
PSH, 6,
ADD,
POP,
HLT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Well first we push 5 to the stack&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;[5]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we push 6:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;[5, 6]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then the add instruction will basically pop these values and add them together and push the result on the stack:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;[5, 6]

// pop the top value, store it in a variable called a
a = pop; // a contains 6
[5] // stack contents

// pop the top value, store it in a variable called b
b = pop; // b contains 5
[] // stack contents

// now we add b and a. Note we do it backwards, in addition
// this doesn't matter, but in other potential instructions
// for instance divide 5 / 6 is not the same as 6 / 5
result = b + a;
push result // push the result to the stack
[11] // stack contents
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where does our stack pointer come into play? Well the stack pointer or &lt;code class="prettyprint"&gt;sp&lt;/code&gt; is set to &lt;code class="prettyprint"&gt;-1&lt;/code&gt;, this means it‚Äôs empty. Arrays are zero-indexed in C, so if the sp was &lt;code class="prettyprint"&gt;0&lt;/code&gt; it would be set to whatever random number the C compiler throws in there because the memory for an array is not zeroed out.&lt;/p&gt;

&lt;p&gt;Now if we push 3 values, the sp would be 2. So here‚Äôs an array with 3 values:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;        -&amp;gt; sp -1
    psh -&amp;gt; sp 0
    psh -&amp;gt; sp 1
    psh -&amp;gt; sp 3

  sp points here (sp = 2)
       |
       V
[1, 5, 9]
 0  1  2 &amp;lt;- array indices or "addresses"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now when we &lt;strong&gt;pop&lt;/strong&gt; a value from the stack, we decrement the stack pointer, so that means that we‚Äôre popping 9, and the top of the stack will be 5:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;    sp points here (sp = 1)
        |
        V
    [1, 5]
     0  1 &amp;lt;- these are the array indices
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When we want to see the top of the stack, we look at the value at the current &lt;code class="prettyprint"&gt;sp&lt;/code&gt;. Okay, hopefully you should know how a stack works! If you‚Äôre still confused, check out &lt;a href="https://en.wikipedia.org/wiki/Stack_(abstract_data_type)"&gt;this&lt;/a&gt; article on wikipedia.&lt;/p&gt;

&lt;p&gt;To implement a stack in C is relatively straight-forward. Along with our &lt;code class="prettyprint"&gt;ip&lt;/code&gt; variable, we should define the &lt;code class="prettyprint"&gt;sp&lt;/code&gt; variable and our array which will be the stack:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;int ip = 0;
int sp = -1;
int stack[256];

...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now if we want to push a value to the stack, we increment the stack pointer &lt;strong&gt;then&lt;/strong&gt; we set the value at the current sp (which we just incremented).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The order here is very important!&lt;/strong&gt; If you set the value first, &lt;u&gt;then&lt;/u&gt; you increment the &lt;code class="prettyprint"&gt;sp&lt;/code&gt; you will get some bad behaviour because we‚Äôre writing to the memory at index &lt;code class="prettyprint"&gt;-1&lt;/code&gt;, not good!&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;// sp = -1
sp++; // sp = 0
stack[sp] = 5; // set value at stack[0] -&amp;gt; 5
// top of stack is now [5]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In our &lt;code class="prettyprint"&gt;eval&lt;/code&gt; function, we can add the stack push like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;void eval(int instr) {
    switch (instr) {
        case HLT: {
            running = false;
            break;
        }
        case PSH: {
            sp++;
            stack[sp] = program[++ip];
            break;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are a few differences between the previous eval function. Firstly, there are braces around the case clauses. If you aren‚Äôt familiar with this trick, it gives the case a scope so you can define variables inside of the clause.&lt;/p&gt;

&lt;p&gt;Secondly, the &lt;code class="prettyprint"&gt;program[++ip]&lt;/code&gt; expression. Why are we doing that here? It‚Äôs because our &lt;code class="prettyprint"&gt;PSH&lt;/code&gt; instruction has an argument. &lt;code class="prettyprint"&gt;PSH, 5&lt;/code&gt;. Immediately after the &lt;code class="prettyprint"&gt;PSH&lt;/code&gt; op is the value that we want to push to the stack.&lt;br&gt;
Here we increment the ip so that its pointing to the &lt;code class="prettyprint"&gt;5&lt;/code&gt;, and then we access that value from the program array. &lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;program = [ PSH, 5, PSH, 6, ]
            0    1  2    3

when pushing:
ip starts at 0 (PSH)
ip++, so ip is now 1 (5)
sp++, allocate some space on the stack
stack[sp] = program[ip], put the value 5 on the stack
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code class="prettyprint"&gt;POP&lt;/code&gt; instruction is as simple as decrementing the stack pointer. However, I wanted to make it so that the pop instruction will print the value it just popped. Because of this, we have to do a little bit more work:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;case POP: {
    // store the value at the stack in val_popped THEN decrement the stack ptr
    int val_popped = stack[sp--];

    // print it out!
    printf("popped %d\n", val_popped);
    break;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, the &lt;code class="prettyprint"&gt;ADD&lt;/code&gt; instruction. This one may be a little trickier to get your head around, and this is where we need our scope trick on the case clause because we‚Äôre introducing some variables.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;case ADD: {
    // first we pop the stack and store it as 'a'
    int a = stack[sp--];

    // then we pop the top of the stack and store it as 'b'
    int b = stack[sp--];

    // we then add the result and push it to the stack
    int result = b + a;
    sp++; // increment stack pointer **before**
    stack[sp] = result; // set the value to the top of the stack

    // all done!
    break;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that the order here is important for certain operations! If you were implementing divide, you might have some troubles because:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;5 / 4 != 4 / 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Stacks are LIFO (last in, first out). Meaning if we pushed 5 then 4, we would pop 4, then pop 5. If we did &lt;code class="prettyprint"&gt;pop() / pop()&lt;/code&gt; this would give us the wrong expression, so it‚Äôs crucial that you get the order correct.&lt;/p&gt;
&lt;h2 id="registers_2"&gt;Registers &lt;a class="head_anchor" href="#registers_2"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Registers are very easy to implement, I mentioned we would have the registers &lt;code class="prettyprint"&gt;A&lt;/code&gt;, &lt;code class="prettyprint"&gt;B&lt;/code&gt;, &lt;code class="prettyprint"&gt;C&lt;/code&gt;, &lt;code class="prettyprint"&gt;D&lt;/code&gt;, &lt;code class="prettyprint"&gt;E&lt;/code&gt;, and &lt;code class="prettyprint"&gt;F&lt;/code&gt;. We can use an enum for this like we did the instruction set.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;typedef enum {
   A, B, C, D, E, F,
   NUM_OF_REGISTERS
} Registers;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last member in the enum &lt;code class="prettyprint"&gt;NUM_OF_REGISTERS&lt;/code&gt; is a little trick so we can get the size of the registers even if you add more.&lt;/p&gt;

&lt;p&gt;We‚Äôll store our registers in an array. Because we use an enum, A = 0, B = 1, C = 2, etc. So when we want to set the register A, it‚Äôs as simple as saying &lt;code class="prettyprint"&gt;register[A] = some_value&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;int registers[NUM_OF_REGISTERS];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Printing out the value in register &lt;code class="prettyprint"&gt;A&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;printf("%d\n", registers[A]); // prints the value at the register A
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="instruction-pointer_3"&gt;Instruction Pointer &lt;a class="head_anchor" href="#instruction-pointer_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;What about branching?&lt;/strong&gt; I‚Äôll leave that to you! Remember an instruction pointer points to the current instruction. Now because this is in the virtual machines source code, your best bet would be to have the instruction pointer as a register that you can read and manipulate from the virtual machines programs.&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;typedef enum {
    A, B, C, D, E, F, PC, SP,
    NUM_OF_REGISTERS
} Registers;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have to port our code to actually use these instruction and stack pointers. A quick and dirty method to do this with the existing code-base is to remove the &lt;code class="prettyprint"&gt;sp&lt;/code&gt; and &lt;code class="prettyprint"&gt;ip&lt;/code&gt; variables at the top and replace them with a define:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint lang-c"&gt;#define sp (registers[SP])
#define ip (registers[IP])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That should be a decent fix so that you don‚Äôt have to re-write a lot of your code, and it should function perfectly. However, this may not scale very well, and it is aliasing some code so I would suggest not using this method, but for a simple toy virtual machine it will suffice.&lt;/p&gt;

&lt;p&gt;When it comes to branching in our code, I‚Äôll give you a hint. With our new &lt;code class="prettyprint"&gt;IP&lt;/code&gt; register, we can branch by writing to this IP a different value. Try this sample below and see what it will do:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;PSH 10
SET IP 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similar to the BASIC program that a lot of people are familiar with:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;10 PRINT "Hello, World"
20 GOTO 10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, since we are pushing values to the stack constantly, we will eventually get a stack overflow once we‚Äôve pushed more than the amount of space we‚Äôve defined.&lt;/p&gt;

&lt;p&gt;Note that each ‚Äòword‚Äô is an instruction, so given the following program:&lt;/p&gt;

&lt;pre&gt;&lt;code class="prettyprint"&gt;              ;  these are the instructions
PSH 10        ;  0 1
PSH 20        ;  2 3
SET IP 0      ;  4 5 6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we wanted to jump to the second &lt;code class="prettyprint"&gt;set&lt;/code&gt; instruction, we would set the &lt;code class="prettyprint"&gt;IP&lt;/code&gt; register to &lt;code class="prettyprint"&gt;2&lt;/code&gt; instead of &lt;code class="prettyprint"&gt;0&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id="fin_3"&gt;Fin &lt;a class="head_anchor" href="#fin_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;And there you have it! If you run &lt;code class="prettyprint"&gt;make&lt;/code&gt; in the projects root directory and you can execute the virtual machine: &lt;code class="prettyprint"&gt;./mac&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You can check out the source code on the github &lt;a href="http://www.github.com/felixangell/mac"&gt;here&lt;/a&gt;. If you want to see a more developed version of the VM with the &lt;code class="prettyprint"&gt;MOV&lt;/code&gt; and &lt;code class="prettyprint"&gt;SET&lt;/code&gt; instructions then check out the &lt;code class="prettyprint"&gt;mac-improved&lt;/code&gt; directory. &lt;br&gt;
The source code for the virtual machine we implemented in this article is in &lt;code class="prettyprint"&gt;mac.c&lt;/code&gt;&lt;/p&gt;
&lt;h3 id="further-reading_3"&gt;Further Reading &lt;a class="head_anchor" href="#further-reading_3"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;If you‚Äôre interested in this topic and want to expand more, there is a lot of resources out there on the internet. Notch wrote a DCPU-16, which is basically a 16 bit virtual machine for the scrapped game 0x10c. &lt;/p&gt;

&lt;p&gt;There are a few implementations of it around GitHub you can check out. You could also look into emulating something like a simple CPU, e.g. a Zilog Z80. &lt;br&gt;
If you want to write an emulator for something like this, go check out the manual and see if you can implement the instruction set and the registers. There‚Äôs a few implementations on GitHub if you need any help.&lt;/p&gt;

&lt;p&gt;If you liked this article, tweet me &lt;a href="http://twitter.com/felix_angell"&gt;@felix_angell&lt;/a&gt;!&lt;br&gt;
Thanks for reading!&lt;/p&gt;
</content>
  </entry>
</feed>
